{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAvila-bioeng/M.R.AI/blob/main/alzheimer's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2PgnhJE236L",
        "outputId": "2d15e484-9067-4ae2-9171-c8da336a9143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle_API\"\n",
        "\n",
        "# Descargar dataset\n",
        "!kaggle datasets download -d ninadaithal/imagesoasis\n",
        "\n",
        "# Descomprimir\n",
        "!unzip -q imagesoasis.zip\n",
        "\n",
        "import os\n",
        "print(\"Contenido del directorio actual:\", os.listdir(\".\"))\n",
        "print(\"Contenido de 'Data' si existe:\", os.listdir(\"Data\") if os.path.exists(\"Data\") else \"No existe 'Data'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG6ot0xX463v",
        "outputId": "589ac866-39a5-4a34-a2d1-250a9fe813dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Dataset URL: https://www.kaggle.com/datasets/ninadaithal/imagesoasis\n",
            "License(s): apache-2.0\n",
            "Downloading imagesoasis.zip to /content\n",
            " 99% 1.22G/1.23G [00:05<00:00, 220MB/s]\n",
            "100% 1.23G/1.23G [00:05<00:00, 224MB/s]\n",
            "Contenido del directorio actual: ['.config', 'gdrive', 'Data', 'imagesoasis.zip', 'sample_data']\n",
            "Contenido de 'Data' si existe: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Original dataset (after unzip)\n",
        "original_dir = \"./Data\"\n",
        "assert os.path.exists(original_dir), \"Data folder not found. Check unzip step.\"\n",
        "\n",
        "# Where weâ€™ll put the reduced version\n",
        "subset_dir = \"./Data_subset\"\n",
        "\n",
        "# Start CLEAN\n",
        "if os.path.exists(subset_dir):\n",
        "    shutil.rmtree(subset_dir)\n",
        "os.makedirs(subset_dir, exist_ok=True)\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "N_PATIENTS_NON_DEMENTED = 120   # ðŸ‘ˆ you can change this if needed\n",
        "\n",
        "classes = [d for d in os.listdir(original_dir)\n",
        "           if os.path.isdir(os.path.join(original_dir, d))]\n",
        "print(\"Classes found:\", classes)\n",
        "\n",
        "for cls in classes:\n",
        "    src_cls_dir = os.path.join(original_dir, cls)\n",
        "    dst_cls_dir = os.path.join(subset_dir, cls)\n",
        "    os.makedirs(dst_cls_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nProcessing class: {cls}\")\n",
        "\n",
        "    if \"non\" not in cls.lower():   # any class that is NOT Non Demented\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Copying ALL images ({len(imgs)})...\")\n",
        "        for fname in imgs:\n",
        "            shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                         os.path.join(dst_cls_dir, fname))\n",
        "\n",
        "    else:\n",
        "        # Non Demented\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Total images in {cls}: {len(imgs)}\")\n",
        "        print(\"  Example names:\", imgs[:5])\n",
        "\n",
        "        # Group by patient: OAS1_XXXX_MR... â†’ patient_id = \"OAS1_XXXX\"\n",
        "        images_by_patient = defaultdict(list)\n",
        "        for fname in imgs:\n",
        "            parts = fname.split('_')\n",
        "            patient_id = \"_\".join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "            images_by_patient[patient_id].append(fname)\n",
        "\n",
        "        print(f\"  Total patients detected: {len(images_by_patient)}\")\n",
        "\n",
        "        patients = list(images_by_patient.keys())\n",
        "        n_keep = min(N_PATIENTS_NON_DEMENTED, len(patients))\n",
        "        selected_patients = random.sample(patients, n_keep)\n",
        "\n",
        "        print(f\"  Patients weâ€™ll keep in {cls}: {n_keep}\")\n",
        "\n",
        "        count_imgs = 0\n",
        "        for pid in selected_patients:\n",
        "            for fname in images_by_patient[pid]:\n",
        "                shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                             os.path.join(dst_cls_dir, fname))\n",
        "                count_imgs += 1\n",
        "\n",
        "        print(f\"  Images copied in {cls} (subset): {count_imgs}\")\n",
        "\n",
        "print(\"\\nâœ… Reduced dataset created at:\", subset_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nYAj9QATL3I",
        "outputId": "7f1f9322-ecab-4eaa-c888-59d8bb507cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n",
            "\n",
            "Processing class: Moderate Dementia\n",
            "  Copying ALL images (488)...\n",
            "\n",
            "Processing class: Non Demented\n",
            "  Total images in Non Demented: 67222\n",
            "  Example names: ['OAS1_0097_MR1_mpr-3_127.jpg', 'OAS1_0136_MR1_mpr-4_144.jpg', 'OAS1_0317_MR1_mpr-2_155.jpg', 'OAS1_0212_MR1_mpr-2_106.jpg', 'OAS1_0162_MR1_mpr-1_128.jpg']\n",
            "  Total patients detected: 266\n",
            "  Patients weâ€™ll keep in Non Demented: 120\n",
            "  Images copied in Non Demented (subset): 29585\n",
            "\n",
            "Processing class: Mild Dementia\n",
            "  Copying ALL images (5002)...\n",
            "\n",
            "Processing class: Very mild Dementia\n",
            "  Copying ALL images (13725)...\n",
            "\n",
            "âœ… Reduced dataset created at: ./Data_subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cls in os.listdir(subset_dir):\n",
        "    cls_path = os.path.join(subset_dir, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        n = len([f for f in os.listdir(cls_path)\n",
        "                 if f.lower().endswith(valid_exts)])\n",
        "        print(f\"{cls}: {n} images in subset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChB0c6zUaG2",
        "outputId": "09652bcd-c40b-4f4b-d6af-ff5244bb3968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moderate Dementia: 488 images in subset\n",
            "Non Demented: 29585 images in subset\n",
            "Mild Dementia: 5002 images in subset\n",
            "Very mild Dementia: 13725 images in subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "subset_dir = \"./Data_subset\"\n",
        "split_root = \"./Data_split\"\n",
        "\n",
        "# Clean split dir\n",
        "if os.path.exists(split_root):\n",
        "    shutil.rmtree(split_root)\n",
        "os.makedirs(split_root, exist_ok=True)\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "for s in splits:\n",
        "    os.makedirs(os.path.join(split_root, s), exist_ok=True)\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "\n",
        "classes = [d for d in os.listdir(subset_dir)\n",
        "           if os.path.isdir(os.path.join(subset_dir, d))]\n",
        "print(\"Classes in subset:\", classes)\n",
        "\n",
        "# Ratios for split\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(subset_dir, cls)\n",
        "    print(f\"\\nSplitting class: {cls}\")\n",
        "\n",
        "    # Group images by patient\n",
        "    images_by_patient = defaultdict(list)\n",
        "    for fname in os.listdir(cls_dir):\n",
        "        if not fname.lower().endswith(valid_exts):\n",
        "            continue\n",
        "        parts = fname.split('_')\n",
        "        patient_id = \"_\".join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "        images_by_patient[patient_id].append(fname)\n",
        "\n",
        "    patients = list(images_by_patient.keys())\n",
        "    random.shuffle(patients)\n",
        "    n_total = len(patients)\n",
        "\n",
        "    # Compute # of patients per split (ensure at least 1 in test if possible)\n",
        "    n_train = max(1, int(TRAIN_RATIO * n_total))\n",
        "    n_val = max(1, int(VAL_RATIO * n_total))\n",
        "    n_test = n_total - n_train - n_val\n",
        "    if n_test <= 0:\n",
        "        n_test = 1\n",
        "        n_train = max(1, n_train - 1)\n",
        "\n",
        "    train_patients = patients[:n_train]\n",
        "    val_patients = patients[n_train:n_train + n_val]\n",
        "    test_patients = patients[n_train + n_val:]\n",
        "\n",
        "    print(f\"  Patients: total={n_total}, train={len(train_patients)}, val={len(val_patients)}, test={len(test_patients)}\")\n",
        "\n",
        "    # Create class dirs inside each split\n",
        "    for s in splits:\n",
        "        os.makedirs(os.path.join(split_root, s, cls), exist_ok=True)\n",
        "\n",
        "    # Copy images to corresponding split\n",
        "    def copy_group(pat_list, split_name):\n",
        "        dst_base = os.path.join(split_root, split_name, cls)\n",
        "        count = 0\n",
        "        for pid in pat_list:\n",
        "            for fname in images_by_patient[pid]:\n",
        "                src = os.path.join(cls_dir, fname)\n",
        "                dst = os.path.join(dst_base, fname)\n",
        "                shutil.copy2(src, dst)\n",
        "                count += 1\n",
        "        print(f\"    {split_name}: {count} images\")\n",
        "\n",
        "    copy_group(train_patients, \"train\")\n",
        "    copy_group(val_patients, \"val\")\n",
        "    copy_group(test_patients, \"test\")\n",
        "\n",
        "print(\"\\nâœ… Patient-wise train/val/test split created in:\", split_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57i7Q8kVX0GH",
        "outputId": "6339bd1f-d327-4605-b18a-6b5fcadbe9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes in subset: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n",
            "\n",
            "Splitting class: Moderate Dementia\n",
            "  Patients: total=2, train=1, val=1, test=0\n",
            "    train: 244 images\n",
            "    val: 244 images\n",
            "    test: 0 images\n",
            "\n",
            "Splitting class: Non Demented\n",
            "  Patients: total=120, train=84, val=18, test=18\n",
            "    train: 21045 images\n",
            "    val: 4148 images\n",
            "    test: 4392 images\n",
            "\n",
            "Splitting class: Mild Dementia\n",
            "  Patients: total=21, train=14, val=3, test=4\n",
            "    train: 3416 images\n",
            "    val: 671 images\n",
            "    test: 915 images\n",
            "\n",
            "Splitting class: Very mild Dementia\n",
            "  Patients: total=58, train=40, val=8, test=10\n",
            "    train: 9394 images\n",
            "    val: 1952 images\n",
            "    test: 2379 images\n",
            "\n",
            "âœ… Patient-wise train/val/test split created in: ./Data_split\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    print(f\"\\n=== {split.upper()} ===\")\n",
        "    split_dir = os.path.join(split_root, split)\n",
        "    for cls in os.listdir(split_dir):\n",
        "        cls_path = os.path.join(split_dir, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            n = len([f for f in os.listdir(cls_path)\n",
        "                     if f.lower().endswith(valid_exts)])\n",
        "            print(f\"  {cls}: {n} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2gTZmdnY65a",
        "outputId": "3a5b8703-1caf-4574-a3a0-3580fc55e866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN ===\n",
            "  Moderate Dementia: 244 images\n",
            "  Non Demented: 21045 images\n",
            "  Mild Dementia: 3416 images\n",
            "  Very mild Dementia: 9394 images\n",
            "\n",
            "=== VAL ===\n",
            "  Moderate Dementia: 244 images\n",
            "  Non Demented: 4148 images\n",
            "  Mild Dementia: 671 images\n",
            "  Very mild Dementia: 1952 images\n",
            "\n",
            "=== TEST ===\n",
            "  Moderate Dementia: 0 images\n",
            "  Non Demented: 4392 images\n",
            "  Mild Dementia: 915 images\n",
            "  Very mild Dementia: 2379 images\n"
          ]
        }
      ]
    }
  ]
}