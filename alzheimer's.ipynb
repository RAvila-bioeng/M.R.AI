{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAvila-bioeng/M.R.AI/blob/main/alzheimer's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2PgnhJE236L",
        "outputId": "ebc32cd6-1f26-4540-a046-74a78ee02957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle_API\"\n",
        "\n",
        "# Descargar dataset\n",
        "!kaggle datasets download -d ninadaithal/imagesoasis\n",
        "\n",
        "# Descomprimir\n",
        "!unzip -q imagesoasis.zip\n",
        "\n",
        "import os\n",
        "print(\"Contenido del directorio actual:\", os.listdir(\".\"))\n",
        "print(\"Contenido de 'Data' si existe:\", os.listdir(\"Data\") if os.path.exists(\"Data\") else \"No existe 'Data'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG6ot0xX463v",
        "outputId": "839d3af2-5598-4efa-90aa-91ff35ee21ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Dataset URL: https://www.kaggle.com/datasets/ninadaithal/imagesoasis\n",
            "License(s): apache-2.0\n",
            "Downloading imagesoasis.zip to /content\n",
            " 99% 1.22G/1.23G [00:08<00:00, 301MB/s]\n",
            "100% 1.23G/1.23G [00:08<00:00, 152MB/s]\n",
            "Contenido del directorio actual: ['.config', 'imagesoasis.zip', 'Data', 'Data_split_2cls', 'gdrive', 'sample_data']\n",
            "Contenido de 'Data' si existe: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "original_dir = \"./Data\"\n",
        "assert os.path.exists(original_dir), \"No existe ./Data. Revisa la celda 1.\"\n",
        "\n",
        "subset_dir = \"./Data_subset\"\n",
        "\n",
        "# Empezar *limpio*\n",
        "if os.path.exists(subset_dir):\n",
        "    shutil.rmtree(subset_dir)\n",
        "os.makedirs(subset_dir, exist_ok=True)\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "N_PATIENTS_NON_DEMENTED = 120  # nº máximo de pacientes sanos\n",
        "\n",
        "classes = [d for d in os.listdir(original_dir)\n",
        "           if os.path.isdir(os.path.join(original_dir, d))]\n",
        "print(\"Clases encontradas en Data:\", classes)\n",
        "\n",
        "for cls in classes:\n",
        "    src_cls_dir = os.path.join(original_dir, cls)\n",
        "    dst_cls_dir = os.path.join(subset_dir, cls)\n",
        "    os.makedirs(dst_cls_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nProcesando clase: {cls}\")\n",
        "\n",
        "    if \"non\" not in cls.lower():   # todas menos Non Demented\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Copiando TODAS las imágenes ({len(imgs)})...\")\n",
        "        for fname in imgs:\n",
        "            shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                         os.path.join(dst_cls_dir, fname))\n",
        "\n",
        "    else:\n",
        "        # Non Demented: reducir por nº de pacientes\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Imágenes totales en {cls}: {len(imgs)}\")\n",
        "        print(\"  Ejemplos de nombres:\", imgs[:5])\n",
        "\n",
        "        images_by_patient = defaultdict(list)\n",
        "        for fname in imgs:\n",
        "            parts = fname.split('_')\n",
        "            # OAS1_0097_MR1_mpr-3_127.jpg → paciente = \"OAS1_0097\"\n",
        "            patient_id = \"_\".join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "            images_by_patient[patient_id].append(fname)\n",
        "\n",
        "        print(f\"  Pacientes totales detectados: {len(images_by_patient)}\")\n",
        "\n",
        "        patients = list(images_by_patient.keys())\n",
        "        n_keep = min(N_PATIENTS_NON_DEMENTED, len(patients))\n",
        "        selected_patients = random.sample(patients, n_keep)\n",
        "\n",
        "        print(f\"  Pacientes que vamos a conservar en {cls}: {n_keep}\")\n",
        "\n",
        "        count_imgs = 0\n",
        "        for pid in selected_patients:\n",
        "            for fname in images_by_patient[pid]:\n",
        "                shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                             os.path.join(dst_cls_dir, fname))\n",
        "                count_imgs += 1\n",
        "\n",
        "        print(f\"  Imágenes copiadas en {cls} (subset): {count_imgs}\")\n",
        "\n",
        "print(\"\\n✅ Data_subset creado en:\", subset_dir)\n",
        "\n",
        "# Comprobar conteos\n",
        "for cls in os.listdir(subset_dir):\n",
        "    cls_path = os.path.join(subset_dir, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        n = len([f for f in os.listdir(cls_path)\n",
        "                 if f.lower().endswith(valid_exts)])\n",
        "        print(f\"{cls}: {n} imágenes en Data_subset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFn0XiTIcs7r",
        "outputId": "e1c4bab4-38cc-42aa-e2c9-c55466e234fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases encontradas en Data: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n",
            "\n",
            "Procesando clase: Moderate Dementia\n",
            "  Copiando TODAS las imágenes (488)...\n",
            "\n",
            "Procesando clase: Non Demented\n",
            "  Imágenes totales en Non Demented: 67222\n",
            "  Ejemplos de nombres: ['OAS1_0076_MR1_mpr-1_114.jpg', 'OAS1_0368_MR2_mpr-4_135.jpg', 'OAS1_0348_MR1_mpr-3_130.jpg', 'OAS1_0001_MR1_mpr-2_140.jpg', 'OAS1_0145_MR2_mpr-1_111.jpg']\n",
            "  Pacientes totales detectados: 266\n",
            "  Pacientes que vamos a conservar en Non Demented: 120\n",
            "  Imágenes copiadas en Non Demented (subset): 30134\n",
            "\n",
            "Procesando clase: Mild Dementia\n",
            "  Copiando TODAS las imágenes (5002)...\n",
            "\n",
            "Procesando clase: Very mild Dementia\n",
            "  Copiando TODAS las imágenes (13725)...\n",
            "\n",
            "✅ Data_subset creado en: ./Data_subset\n",
            "Moderate Dementia: 488 imágenes en Data_subset\n",
            "Non Demented: 30134 imágenes en Data_subset\n",
            "Mild Dementia: 5002 imágenes en Data_subset\n",
            "Very mild Dementia: 13725 imágenes en Data_subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# Directorio de entrada (ya balanceado por pacientes sanos)\n",
        "subset_dir = \"./Data_subset\"\n",
        "\n",
        "# Nuevo directorio de salida para el split binario\n",
        "split_root = \"./Data_split_2cls\"\n",
        "os.makedirs(split_root, exist_ok=True)\n",
        "\n",
        "# Mapa de clases original -> clase lógica binaria\n",
        "CLASS_MAP = {\n",
        "    \"Non Demented\": \"Non Demented\",\n",
        "    \"Very mild Dementia\": \"Demented\",\n",
        "    \"Mild Dementia\": \"Demented\",\n",
        "    \"Moderate Dementia\": \"Demented\",\n",
        "}\n",
        "\n",
        "logical_classes = sorted(set(CLASS_MAP.values()))\n",
        "print(\"Logical classes:\", logical_classes)\n",
        "\n",
        "# Crear estructura de carpetas: train/val/test + clases\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in logical_classes:\n",
        "        os.makedirs(os.path.join(split_root, split, cls), exist_ok=True)\n",
        "\n",
        "# Agrupar imágenes por (clase lógica, paciente)\n",
        "class_patient_images = {cls: defaultdict(list) for cls in logical_classes}\n",
        "\n",
        "for orig_class in os.listdir(subset_dir):\n",
        "    orig_class_path = os.path.join(subset_dir, orig_class)\n",
        "    if not os.path.isdir(orig_class_path):\n",
        "        continue\n",
        "\n",
        "    if orig_class not in CLASS_MAP:\n",
        "        print(f\"Saltando clase desconocida: {orig_class}\")\n",
        "        continue\n",
        "\n",
        "    logical_class = CLASS_MAP[orig_class]\n",
        "\n",
        "    for fname in os.listdir(orig_class_path):\n",
        "        fpath = os.path.join(orig_class_path, fname)\n",
        "        if not os.path.isfile(fpath):\n",
        "            continue\n",
        "\n",
        "        # Filtrar solo imágenes\n",
        "        if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "            continue\n",
        "\n",
        "        # Extraer patient_id del nombre de archivo (adaptado al patrón OASIS)\n",
        "        parts = fname.split(\"_\")\n",
        "        if len(parts) >= 2 and parts[0].startswith(\"OAS1\"):\n",
        "            patient_id = parts[0] + \"_\" + parts[1]\n",
        "        else:\n",
        "            # Fallback por si acaso\n",
        "            patient_id = parts[0]\n",
        "\n",
        "        class_patient_images[logical_class][patient_id].append(fpath)\n",
        "\n",
        "# Función para hacer split por pacientes\n",
        "def split_patients(patients, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
        "    random.seed(seed)\n",
        "    patients = list(patients)\n",
        "    random.shuffle(patients)\n",
        "\n",
        "    n = len(patients)\n",
        "    if n == 0:\n",
        "        return [], [], []\n",
        "\n",
        "    n_train = max(1, int(train_ratio * n))\n",
        "    n_val = max(1, int(val_ratio * n))\n",
        "    n_test = n - n_train - n_val\n",
        "\n",
        "    # Ajustes por si n_test queda a 0\n",
        "    if n_test <= 0:\n",
        "        n_test = 1\n",
        "        if n_val > 1:\n",
        "            n_val -= 1\n",
        "        else:\n",
        "            n_train = max(1, n_train - 1)\n",
        "\n",
        "    train_patients = patients[:n_train]\n",
        "    val_patients = patients[n_train:n_train + n_val]\n",
        "    test_patients = patients[n_train + n_val:]\n",
        "\n",
        "    return train_patients, val_patients, test_patients\n",
        "\n",
        "# Hacer el split y copiar archivos\n",
        "for logical_class in logical_classes:\n",
        "    patients_dict = class_patient_images[logical_class]\n",
        "    patients = list(patients_dict.keys())\n",
        "    print(f\"\\nClase '{logical_class}': {len(patients)} pacientes\")\n",
        "\n",
        "    train_p, val_p, test_p = split_patients(patients)\n",
        "\n",
        "    print(f\"  Train: {len(train_p)} pacientes\")\n",
        "    print(f\"  Val:   {len(val_p)} pacientes\")\n",
        "    print(f\"  Test:  {len(test_p)} pacientes\")\n",
        "\n",
        "    for split_name, split_pat_list in [(\"train\", train_p),\n",
        "                                       (\"val\", val_p),\n",
        "                                       (\"test\", test_p)]:\n",
        "        for pid in split_pat_list:\n",
        "            for src_path in patients_dict[pid]:\n",
        "                dst_path = os.path.join(\n",
        "                    split_root,\n",
        "                    split_name,\n",
        "                    logical_class,\n",
        "                    os.path.basename(src_path),\n",
        "                )\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "\n",
        "print(\"\\nCopiado terminado. Comprobando número de imágenes por split y clase...\\n\")\n",
        "\n",
        "# Comprobación final de conteos\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    print(f\"Split: {split}\")\n",
        "    for cls in logical_classes:\n",
        "        cls_dir = os.path.join(split_root, split, cls)\n",
        "        if not os.path.isdir(cls_dir):\n",
        "            print(f\"  {cls}: 0 imágenes (directorio no encontrado)\")\n",
        "            continue\n",
        "        n_images = sum(\n",
        "            1 for f in os.listdir(cls_dir)\n",
        "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "        )\n",
        "        print(f\"  {cls}: {n_images} imágenes\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nYAj9QATL3I",
        "outputId": "4fbd597c-991c-4a5a-d41e-673d7b040952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logical classes: ['Demented', 'Non Demented']\n",
            "\n",
            "Clase 'Demented': 81 pacientes\n",
            "  Train: 56 pacientes\n",
            "  Val:   12 pacientes\n",
            "  Test:  13 pacientes\n",
            "\n",
            "Clase 'Non Demented': 120 pacientes\n",
            "  Train: 84 pacientes\n",
            "  Val:   18 pacientes\n",
            "  Test:  18 pacientes\n",
            "\n",
            "Copiado terminado. Comprobando número de imágenes por split y clase...\n",
            "\n",
            "Split: train\n",
            "  Demented: 13298 imágenes\n",
            "  Non Demented: 21289 imágenes\n",
            "\n",
            "Split: val\n",
            "  Demented: 2867 imágenes\n",
            "  Non Demented: 4331 imágenes\n",
            "\n",
            "Split: test\n",
            "  Demented: 3050 imágenes\n",
            "  Non Demented: 4514 imágenes\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    print(f\"\\n=== {split.upper()} ===\")\n",
        "    split_dir = os.path.join(split_root, split)\n",
        "    for cls in os.listdir(split_dir):\n",
        "        cls_path = os.path.join(split_dir, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            n = len([f for f in os.listdir(cls_path)\n",
        "                     if f.lower().endswith(valid_exts)])\n",
        "            print(f\"  {cls}: {n} imágenes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChB0c6zUaG2",
        "outputId": "a39cb319-b1a9-41d7-a9e3-c0c7226af128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN ===\n",
            "  Non Demented: 21289 imágenes\n",
            "  Demented: 13298 imágenes\n",
            "\n",
            "=== VAL ===\n",
            "  Non Demented: 4331 imágenes\n",
            "  Demented: 2867 imágenes\n",
            "\n",
            "=== TEST ===\n",
            "  Non Demented: 4514 imágenes\n",
            "  Demented: 3050 imágenes\n"
          ]
        }
      ]
    }
  ]
}