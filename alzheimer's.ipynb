{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAvila-bioeng/M.R.AI/blob/main/alzheimer's.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2PgnhJE236L",
        "outputId": "2febfe9f-86f8-47d2-a888-37fa29b27a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Kaggle_API\"\n",
        "\n",
        "# Descargar dataset\n",
        "!kaggle datasets download -d ninadaithal/imagesoasis\n",
        "\n",
        "# Descomprimir\n",
        "!unzip -q imagesoasis.zip\n",
        "\n",
        "import os\n",
        "print(\"Contenido del directorio actual:\", os.listdir(\".\"))\n",
        "print(\"Contenido de 'Data' si existe:\", os.listdir(\"Data\") if os.path.exists(\"Data\") else \"No existe 'Data'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG6ot0xX463v",
        "outputId": "0285a7c4-f03b-4d64-a14a-1da7dc6222a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Dataset URL: https://www.kaggle.com/datasets/ninadaithal/imagesoasis\n",
            "License(s): apache-2.0\n",
            "Downloading imagesoasis.zip to /content\n",
            " 99% 1.22G/1.23G [00:05<00:00, 239MB/s]\n",
            "100% 1.23G/1.23G [00:06<00:00, 218MB/s]\n",
            "Contenido del directorio actual: ['.config', 'gdrive', 'Data', 'imagesoasis.zip', 'sample_data']\n",
            "Contenido de 'Data' si existe: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "original_dir = \"./Data\"\n",
        "assert os.path.exists(original_dir), \"No existe ./Data. Revisa la celda 1.\"\n",
        "\n",
        "subset_dir = \"./Data_subset\"\n",
        "\n",
        "# Empezar *limpio*\n",
        "if os.path.exists(subset_dir):\n",
        "    shutil.rmtree(subset_dir)\n",
        "os.makedirs(subset_dir, exist_ok=True)\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "N_PATIENTS_NON_DEMENTED = 120  # nº máximo de pacientes sanos\n",
        "\n",
        "classes = [d for d in os.listdir(original_dir)\n",
        "           if os.path.isdir(os.path.join(original_dir, d))]\n",
        "print(\"Clases encontradas en Data:\", classes)\n",
        "\n",
        "for cls in classes:\n",
        "    src_cls_dir = os.path.join(original_dir, cls)\n",
        "    dst_cls_dir = os.path.join(subset_dir, cls)\n",
        "    os.makedirs(dst_cls_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"\\nProcesando clase: {cls}\")\n",
        "\n",
        "    if \"non\" not in cls.lower():   # todas menos Non Demented\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Copiando TODAS las imágenes ({len(imgs)})...\")\n",
        "        for fname in imgs:\n",
        "            shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                         os.path.join(dst_cls_dir, fname))\n",
        "\n",
        "    else:\n",
        "        # Non Demented: reducir por nº de pacientes\n",
        "        imgs = [f for f in os.listdir(src_cls_dir)\n",
        "                if f.lower().endswith(valid_exts)]\n",
        "        print(f\"  Imágenes totales en {cls}: {len(imgs)}\")\n",
        "        print(\"  Ejemplos de nombres:\", imgs[:5])\n",
        "\n",
        "        images_by_patient = defaultdict(list)\n",
        "        for fname in imgs:\n",
        "            parts = fname.split('_')\n",
        "            # OAS1_0097_MR1_mpr-3_127.jpg → paciente = \"OAS1_0097\"\n",
        "            patient_id = \"_\".join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "            images_by_patient[patient_id].append(fname)\n",
        "\n",
        "        print(f\"  Pacientes totales detectados: {len(images_by_patient)}\")\n",
        "\n",
        "        patients = list(images_by_patient.keys())\n",
        "        n_keep = min(N_PATIENTS_NON_DEMENTED, len(patients))\n",
        "        selected_patients = random.sample(patients, n_keep)\n",
        "\n",
        "        print(f\"  Pacientes que vamos a conservar en {cls}: {n_keep}\")\n",
        "\n",
        "        count_imgs = 0\n",
        "        for pid in selected_patients:\n",
        "            for fname in images_by_patient[pid]:\n",
        "                shutil.copy2(os.path.join(src_cls_dir, fname),\n",
        "                             os.path.join(dst_cls_dir, fname))\n",
        "                count_imgs += 1\n",
        "\n",
        "        print(f\"  Imágenes copiadas en {cls} (subset): {count_imgs}\")\n",
        "\n",
        "print(\"\\n✅ Data_subset creado en:\", subset_dir)\n",
        "\n",
        "# Comprobar conteos\n",
        "for cls in os.listdir(subset_dir):\n",
        "    cls_path = os.path.join(subset_dir, cls)\n",
        "    if os.path.isdir(cls_path):\n",
        "        n = len([f for f in os.listdir(cls_path)\n",
        "                 if f.lower().endswith(valid_exts)])\n",
        "        print(f\"{cls}: {n} imágenes en Data_subset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFn0XiTIcs7r",
        "outputId": "ac9da63b-42bd-4643-fd36-afce20add1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases encontradas en Data: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n",
            "\n",
            "Procesando clase: Moderate Dementia\n",
            "  Copiando TODAS las imágenes (488)...\n",
            "\n",
            "Procesando clase: Non Demented\n",
            "  Imágenes totales en Non Demented: 67222\n",
            "  Ejemplos de nombres: ['OAS1_0097_MR1_mpr-3_127.jpg', 'OAS1_0136_MR1_mpr-4_144.jpg', 'OAS1_0317_MR1_mpr-2_155.jpg', 'OAS1_0212_MR1_mpr-2_106.jpg', 'OAS1_0162_MR1_mpr-1_128.jpg']\n",
            "  Pacientes totales detectados: 266\n",
            "  Pacientes que vamos a conservar en Non Demented: 120\n",
            "  Imágenes copiadas en Non Demented (subset): 30500\n",
            "\n",
            "Procesando clase: Mild Dementia\n",
            "  Copiando TODAS las imágenes (5002)...\n",
            "\n",
            "Procesando clase: Very mild Dementia\n",
            "  Copiando TODAS las imágenes (13725)...\n",
            "\n",
            "✅ Data_subset creado en: ./Data_subset\n",
            "Moderate Dementia: 488 imágenes en Data_subset\n",
            "Non Demented: 30500 imágenes en Data_subset\n",
            "Mild Dementia: 5002 imágenes en Data_subset\n",
            "Very mild Dementia: 13725 imágenes en Data_subset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "subset_dir = \"./Data_subset\"          # de aquí leemos\n",
        "split_root = \"./Data_split_3cls\"      # aquí escribimos el nuevo split\n",
        "\n",
        "# Limpiar split anterior (si existe)\n",
        "if os.path.exists(split_root):\n",
        "    shutil.rmtree(split_root)\n",
        "os.makedirs(split_root, exist_ok=True)\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "for s in splits:\n",
        "    os.makedirs(os.path.join(split_root, s), exist_ok=True)\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')\n",
        "\n",
        "# Mapeo de clases físicas -> clases lógicas\n",
        "# Moderate Dementia se fusiona con Mild Dementia\n",
        "CLASS_MAP = {\n",
        "    \"Non Demented\": \"Non Demented\",\n",
        "    \"Very mild Dementia\": \"Very mild Dementia\",\n",
        "    \"Mild Dementia\": \"Mild Dementia\",\n",
        "    \"Moderate Dementia\": \"Mild Dementia\",\n",
        "}\n",
        "\n",
        "# 1) Construimos un diccionario: logical_class -> patient_id -> lista de rutas de imagen\n",
        "class_patient_images = defaultdict(lambda: defaultdict(list))\n",
        "\n",
        "physical_classes = [d for d in os.listdir(subset_dir)\n",
        "                    if os.path.isdir(os.path.join(subset_dir, d))]\n",
        "print(\"Clases físicas en subset:\", physical_classes)\n",
        "\n",
        "for phys_cls in physical_classes:\n",
        "    if phys_cls not in CLASS_MAP:\n",
        "        print(f\"  Aviso: clase {phys_cls} no está en CLASS_MAP, se ignora.\")\n",
        "        continue\n",
        "\n",
        "    logical_cls = CLASS_MAP[phys_cls]\n",
        "    cls_dir = os.path.join(subset_dir, phys_cls)\n",
        "\n",
        "    print(f\"\\nLeyendo clase física '{phys_cls}' como clase lógica '{logical_cls}'\")\n",
        "\n",
        "    for fname in os.listdir(cls_dir):\n",
        "        if not fname.lower().endswith(valid_exts):\n",
        "            continue\n",
        "\n",
        "        # Sacar patient_id de nombres tipo: OAS1_0028_MR1_mpr-1_100.jpg\n",
        "        parts = fname.split('_')\n",
        "        patient_id = \"_\".join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
        "\n",
        "        full_path = os.path.join(cls_dir, fname)\n",
        "        class_patient_images[logical_cls][patient_id].append(full_path)\n",
        "\n",
        "# 2) Hacemos el split por paciente para cada clase lógica\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "for logical_cls, patients_dict in class_patient_images.items():\n",
        "    print(f\"\\n=== Splitting logical class: {logical_cls} ===\")\n",
        "\n",
        "    patient_ids = list(patients_dict.keys())\n",
        "    random.shuffle(patient_ids)\n",
        "    n_total = len(patient_ids)\n",
        "\n",
        "    # nº de pacientes por split\n",
        "    n_train = max(1, int(TRAIN_RATIO * n_total))\n",
        "    n_val = max(1, int(VAL_RATIO * n_total))\n",
        "    n_test = n_total - n_train - n_val\n",
        "    if n_test <= 0:\n",
        "        n_test = 1\n",
        "        n_train = max(1, n_train - 1)\n",
        "\n",
        "    train_patients = patient_ids[:n_train]\n",
        "    val_patients = patient_ids[n_train:n_train + n_val]\n",
        "    test_patients = patient_ids[n_train + n_val:]\n",
        "\n",
        "    print(f\"  Pacientes: total={n_total}, train={len(train_patients)}, val={len(val_patients)}, test={len(test_patients)}\")\n",
        "\n",
        "    # Crear carpetas de clase lógica en cada split\n",
        "    for s in splits:\n",
        "        os.makedirs(os.path.join(split_root, s, logical_cls), exist_ok=True)\n",
        "\n",
        "    def copy_group(pat_list, split_name):\n",
        "        dst_base = os.path.join(split_root, split_name, logical_cls)\n",
        "        count = 0\n",
        "        for pid in pat_list:\n",
        "            for src_path in patients_dict[pid]:\n",
        "                fname = os.path.basename(src_path)\n",
        "                dst_path = os.path.join(dst_base, fname)\n",
        "\n",
        "                # Si por alguna razón ya existe ese nombre, renombra para evitar sobrescribir\n",
        "                if os.path.exists(dst_path):\n",
        "                    name, ext = os.path.splitext(fname)\n",
        "                    dst_path = os.path.join(dst_base, f\"{name}_dup{ext}\")\n",
        "\n",
        "                shutil.copy2(src_path, dst_path)\n",
        "                count += 1\n",
        "        print(f\"    {split_name}: {count} imágenes\")\n",
        "\n",
        "    copy_group(train_patients, \"train\")\n",
        "    copy_group(val_patients, \"val\")\n",
        "    copy_group(test_patients, \"test\")\n",
        "\n",
        "print(\"\\n✅ Split de 3 clases creado en:\", split_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nYAj9QATL3I",
        "outputId": "18e1e6b0-4b8e-4116-b108-acb9d2dbda79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases físicas en subset: ['Moderate Dementia', 'Non Demented', 'Mild Dementia', 'Very mild Dementia']\n",
            "\n",
            "Leyendo clase física 'Moderate Dementia' como clase lógica 'Mild Dementia'\n",
            "\n",
            "Leyendo clase física 'Non Demented' como clase lógica 'Non Demented'\n",
            "\n",
            "Leyendo clase física 'Mild Dementia' como clase lógica 'Mild Dementia'\n",
            "\n",
            "Leyendo clase física 'Very mild Dementia' como clase lógica 'Very mild Dementia'\n",
            "\n",
            "=== Splitting logical class: Mild Dementia ===\n",
            "  Pacientes: total=23, train=16, val=3, test=4\n",
            "    train: 3843 imágenes\n",
            "    val: 732 imágenes\n",
            "    test: 915 imágenes\n",
            "\n",
            "=== Splitting logical class: Non Demented ===\n",
            "  Pacientes: total=120, train=84, val=18, test=18\n",
            "    train: 21533 imágenes\n",
            "    val: 4697 imágenes\n",
            "    test: 4270 imágenes\n",
            "\n",
            "=== Splitting logical class: Very mild Dementia ===\n",
            "  Pacientes: total=58, train=40, val=8, test=10\n",
            "    train: 9638 imágenes\n",
            "    val: 1891 imágenes\n",
            "    test: 2196 imágenes\n",
            "\n",
            "✅ Split de 3 clases creado en: ./Data_split_3cls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    print(f\"\\n=== {split.upper()} ===\")\n",
        "    split_dir = os.path.join(split_root, split)\n",
        "    for cls in os.listdir(split_dir):\n",
        "        cls_path = os.path.join(split_dir, cls)\n",
        "        if os.path.isdir(cls_path):\n",
        "            n = len([f for f in os.listdir(cls_path)\n",
        "                     if f.lower().endswith(valid_exts)])\n",
        "            print(f\"  {cls}: {n} imágenes\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChB0c6zUaG2",
        "outputId": "5475dce0-1527-456a-f140-360821ddc57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAIN ===\n",
            "  Non Demented: 21533 imágenes\n",
            "  Mild Dementia: 3843 imágenes\n",
            "  Very mild Dementia: 9638 imágenes\n",
            "\n",
            "=== VAL ===\n",
            "  Non Demented: 4697 imágenes\n",
            "  Mild Dementia: 732 imágenes\n",
            "  Very mild Dementia: 1891 imágenes\n",
            "\n",
            "=== TEST ===\n",
            "  Non Demented: 4270 imágenes\n",
            "  Mild Dementia: 915 imágenes\n",
            "  Very mild Dementia: 2196 imágenes\n"
          ]
        }
      ]
    }
  ]
}